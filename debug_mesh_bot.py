#!/usr/bin/env python3
"""
Bot Mesh Debug - Version simplifi√©e pour tester l'IA
"""

import time
import requests
import threading
import re
from datetime import datetime
import meshtastic
import meshtastic.serial_interface
from pubsub import pub

# Configuration
SERIAL_PORT = "/dev/ttyACM0"
LLAMA_HOST = "127.0.0.1"
LLAMA_PORT = 8080

class DebugMeshBot:
    def __init__(self):
        self.interface = None
        self.running = False
        
    def test_llama(self):
        """Test du serveur llama"""
        try:
            print("üß™ Test du serveur llama.cpp...")
            response = requests.get(f"http://{LLAMA_HOST}:{LLAMA_PORT}/health", timeout=3)
            print(f"‚úÖ Serveur r√©pond avec code: {response.status_code}")
            return response.status_code == 200
        except Exception as e:
            print(f"‚ùå Erreur connexion llama: {e}")
            return False
    
    def clean_ai_response(self, content):
        """Nettoie la r√©ponse de l'IA en supprimant les balises de r√©flexion"""
        try:
            print(f"üîß Contenu original avant nettoyage: '{content}'")
            
            # Supprimer seulement les balises de r√©flexion principales
            patterns_to_remove = [
                r'<think>.*?</think>',
                r'<thinking>.*?</thinking>'
            ]
            
            for pattern in patterns_to_remove:
                content = re.sub(pattern, '', content, flags=re.DOTALL | re.IGNORECASE)
            
            # Nettoyer les espaces multiples
            content = re.sub(r'\s+', ' ', content).strip()
            
            # Si vraiment vide, message simple
            if not content or len(content.strip()) < 2:
                content = "Pas de r√©ponse"
            
            print(f"‚úÖ Contenu apr√®s nettoyage: '{content}'")
            return content
            
        except Exception as e:
            print(f"‚ùå Erreur nettoyage: {e}")
            return content if content else "Erreur"
    
    def query_llama(self, prompt):
        """Requ√™te au serveur llama avec API de chat et prompt syst√®me"""
        try:
            print(f"ü§ñ Envoi √† llama.cpp: '{prompt}'")
            
            data = {
                "messages": [
                    {
                        "role": "system",
                        "content": "Tu es un assistant accessible via le r√©seau Meshtastic en LoRa. Tu dois r√©pondre en fran√ßais de mani√®re tr√®s courte, claire et efficace. Utilise seulement quelques mots ou phrases, avec un maximum de 200 caract√®res par r√©ponse. Ne commence jamais ta r√©ponse par des balises de r√©flexion."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 32000,
                "temperature": 0.6,
                "top_p": 0.95,
                "top_k": 20
            }
            
            print(f"üìä Messages envoy√©s: {len(data['messages'])} messages")
            
            start_time = time.time()
            
            # Augmenter le timeout √† 180s
            response = requests.post(f"http://{LLAMA_HOST}:{LLAMA_PORT}/v1/chat/completions", 
                                   json=data, timeout=180)
            end_time = time.time()
            
            print(f"‚è±Ô∏è  Temps de r√©ponse: {end_time - start_time:.2f}s")
            print(f"üìà Code de r√©ponse HTTP: {response.status_code}")
            
            if response.status_code != 200:
                print(f"‚ùå Erreur HTTP: {response.text}")
                return "Erreur serveur"
            
            result = response.json()
            print(f"üìÑ R√©ponse brute: {result}")
            
            # Extraire le contenu de la r√©ponse du chat
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content'].strip()
            else:
                content = "Pas de r√©ponse"
            
            # Nettoyer le contenu avec la nouvelle fonction
            content = self.clean_ai_response(content)
            
            return content
            
        except Exception as e:
            error_msg = f"Erreur IA: {str(e)}"
            print(f"‚ùå {error_msg}")
            return error_msg
    
    def format_timestamp(self):
        return datetime.now().strftime("%H:%M:%S")
    
    def on_message(self, packet, interface):
        """Gestionnaire des messages - Version debug avec messages priv√©s uniquement"""
        try:
            # Filtrer silencieusement les paquets de t√©l√©m√©trie pour nettoyer les logs
            if 'decoded' in packet:
                portnum = packet['decoded'].get('portnum', '')
                if portnum in ['TELEMETRY_APP', 'NODEINFO_APP', 'POSITION_APP', 'ROUTING_APP']:
                    return  # Ignorer silencieusement ces paquets
            
            print(f"\n[{self.format_timestamp()}] üì° PACKET RE√áU:")
            print(f"  From: {packet.get('from', 'N/A')}")
            print(f"  To: {packet.get('to', 'N/A')}")
            print(f"  PKI Encrypted: {packet.get('pkiEncrypted', False)}")
            print(f"  Decoded: {'Oui' if 'decoded' in packet else 'Non'}")
            
            # V√©rifier si c'est un message priv√© (destin√© √† notre n≈ìud)
            to_id = packet.get('to', 0)
            my_id = None
            
            if hasattr(self.interface, 'localNode') and self.interface.localNode:
                my_id = getattr(self.interface.localNode, 'nodeNum', 0)
                print(f"  Mon ID: {my_id} (0x{my_id:08x})")
            
            # V√©rifier si c'est un message priv√©
            is_private = (to_id == my_id) if my_id else False
            is_broadcast = to_id == 0xFFFFFFFF or to_id == 0  # Adresses de broadcast communes
            
            print(f"  üîí Message priv√©: {'Oui' if is_private else 'Non'}")
            print(f"  üì¢ Message public: {'Oui' if is_broadcast else 'Non'}")
            
            if 'decoded' not in packet:
                print("  ‚ö†Ô∏è  Message non d√©cod√© (crypt√© ou erreur)")
                return
            
            decoded = packet['decoded']
            portnum = decoded.get('portnum', '')
            print(f"  Type: {portnum}")
            
            if portnum == 'TEXT_MESSAGE_APP':
                # G√©rer les diff√©rents formats de message
                message = ""
                
                if 'text' in decoded:
                    message = decoded['text']
                elif 'payload' in decoded:
                    payload = decoded['payload']
                    if isinstance(payload, bytes):
                        try:
                            message = payload.decode('utf-8')
                        except UnicodeDecodeError:
                            message = payload.decode('utf-8', errors='replace')
                    else:
                        message = str(payload)
                
                sender_id = packet.get('from', 0)
                
                print(f"  üí¨ MESSAGE: '{message}'")
                print(f"  üë§ SENDER: {sender_id}")
                
                # NOUVELLE LOGIQUE: Traiter SEULEMENT les commandes /bot en priv√©
                if message.startswith('/bot '):
                    if not is_private:
                        print(f"  üö´ COMMANDE BOT IGNOR√âE (message public)")
                        print(f"  üí° Le bot ne r√©pond qu'aux messages priv√©s")
                        return
                    
                    prompt = message[5:].strip()
                    print(f"  üéØ COMMANDE BOT PRIV√âE D√âTECT√âE: '{prompt}'")
                    
                    if prompt:
                        print(f"  üöÄ D√âBUT DU TRAITEMENT...")
                        
                        # Traiter avec l'IA
                        response = self.query_llama(prompt)
                        
                        # Limiter pour Meshtastic
                        if len(response) > 200:
                            response = response[:197] + "..."
                        
                        final_response = f"ü§ñ {response}"
                        
                        print(f"  üì§ ENVOI R√âPONSE PRIV√âE √† {sender_id}: '{final_response}'")
                        
                        # Tenter plusieurs m√©thodes pour l'envoi priv√©
                        try:
                            # M√©thode 1: destinationId (nouvelle API)
                            self.interface.sendText(final_response, destinationId=sender_id)
                            print(f"  ‚úÖ R√âPONSE PRIV√âE ENVOY√âE (m√©thode destinationId)")
                        except Exception as e1:
                            print(f"  ‚ö†Ô∏è M√©thode destinationId √©chou√©e: {e1}")
                            try:
                                # M√©thode 2: dest (ancienne API)  
                                self.interface.sendText(final_response, dest=sender_id)
                                print(f"  ‚úÖ R√âPONSE PRIV√âE ENVOY√âE (m√©thode dest)")
                            except Exception as e2:
                                print(f"  ‚ö†Ô∏è M√©thode dest √©chou√©e: {e2}")
                                try:
                                    # M√©thode 3: Conversion en format hex
                                    hex_id = f"!{sender_id:08x}"
                                    self.interface.sendText(final_response, destinationId=hex_id)
                                    print(f"  ‚úÖ R√âPONSE PRIV√âE ENVOY√âE (format hex: {hex_id})")
                                except Exception as e3:
                                    print(f"  ‚ùå Toutes les m√©thodes priv√©es ont √©chou√©: {e3}")
                                    print(f"  üì¢ Fallback: envoi public")
                                    self.interface.sendText(f"@{sender_id:08x} {final_response}")
                            
                        print(f"  ‚úÖ Tentative d'envoi priv√© termin√©e")
                    else:
                        # R√©pondre en priv√© m√™me pour l'usage
                        self.interface.sendText("Usage: /bot <question>", destinationId=sender_id)
                        
                elif message.startswith('/bot ') and not is_private:
                    print(f"  üì¢ Commande /bot publique ignor√©e")
                    
                else:
                    print(f"  üìù Message normal (pas /bot): '{message}'")
            
        except Exception as e:
            print(f"‚ùå Erreur traitement: {e}")
            import traceback
            traceback.print_exc()
    
    def interactive_loop(self):
        """Boucle interactive simplifi√©e"""
        while self.running:
            try:
                command = input(f"\n[{self.format_timestamp()}] > ")
                
                if command.lower() in ['quit', 'exit', 'q']:
                    self.running = False
                    break
                elif command.startswith('test '):
                    # Test direct de l'IA
                    prompt = command[5:]
                    print(f"üß™ TEST DIRECT LLAMA avec: '{prompt}'")
                    response = self.query_llama(prompt)
                    print(f"üìã R√©sultat: {response}")
                elif command.startswith('bot '):
                    question = command[4:]
                    bot_command = f"/bot {question}"
                    print(f"üì§ Envoi via Meshtastic: '{bot_command}'")
                    self.interface.sendText(bot_command)
                elif command == 'help':
                    print("Commandes:")
                    print("  test <prompt>  - Test direct llama.cpp")
                    print("  bot <question> - Via Meshtastic")
                    print("  quit           - Quitter")
                else:
                    print("Tapez 'help' pour l'aide")
                    
            except KeyboardInterrupt:
                self.running = False
                break
            except Exception as e:
                print(f"Erreur interactive: {e}")
    
    def start(self):
        """D√©marrage"""
        print("üöÄ Bot Mesh Debug")
        
        # Test llama
        if not self.test_llama():
            print("‚ùå Impossible de continuer sans llama.cpp")
            return False
        
        try:
            print(f"üîå Connexion √† {SERIAL_PORT}...")
            self.interface = meshtastic.serial_interface.SerialInterface(SERIAL_PORT)
            time.sleep(3)
            
            print("‚úÖ Interface Meshtastic OK")
            
            # Utiliser pubsub au lieu de onReceive
            print("üì° Configuration pubsub...")
            pub.subscribe(self.on_message, "meshtastic.receive")
            
            self.running = True
            
            print("\n" + "="*60)
            print("üéØ MODE DEBUG ACTIF")
            print("Commandes:")
            print("  test salut       - Test direct llama.cpp")
            print("  bot Bonjour IA   - Via Meshtastic + callback")
            print("  quit             - Quitter")
            print("="*60)
            
            # Thread interactif
            threading.Thread(target=self.interactive_loop, daemon=True).start()
            
            # Boucle principale
            while self.running:
                time.sleep(0.1)
                
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
            return False
    
    def stop(self):
        print("‚ÑπÔ∏è Arr√™t...")
        self.running = False
        if self.interface:
            self.interface.close()

def main():
    bot = DebugMeshBot()
    try:
        bot.start()
    except KeyboardInterrupt:
        pass
    finally:
        bot.stop()

if __name__ == "__main__":
    main()
